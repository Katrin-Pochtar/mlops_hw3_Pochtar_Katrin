{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0IjE4AOTGy4jSrTBvo8sd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Семинар 2 — Версионирование данных и моделей с помощью DVC и Git**\n","\n","## **Цель семинара**\n","\n","На этом семинаре вы познакомитесь с инструментом **DVC (Data Version Control)** — системой для версионирования данных и моделей в ML-проектах.\n","\n","Вы научитесь:\n","- Версионировать большие файлы (датасеты, модели) вместе с кодом.\n","- Настраивать удалённое хранилище для данных.\n","- Сохранять и восстанавливать версии моделей.\n","- Создавать пайплайны для автоматического воспроизводства экспериментов.\n","\n","---\n","\n","## **1. Введение**\n","\n","Git отлично справляется с версиями кода, но в ML-проектах у нас есть ещё:\n","- большие датасеты (гигабайты, терабайты);\n","- бинарные модели (.pkl, .h5, .pt);\n","- пайплайны обработки данных.\n","\n","Git не подходит для таких файлов — он не умеет эффективно хранить и сравнивать большие бинарные данные.\n","\n","Поэтому используется **DVC** — инструмент для версионирования данных и моделей поверх Git.  \n","Он позволяет:\n","- хранить только *метаданные* файлов в Git;\n","- синхронизировать сами данные в отдельном хранилище (локальном или облачном);\n","- воспроизводить эксперименты и пайплайны.\n"],"metadata":{"id":"QWtDsy6fw-mH"}},{"cell_type":"code","source":["!pip install dvc -q"],"metadata":{"id":"syqF4NSqw_y6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2. Инициализация проекта (Git + DVC)**\n","\n","В реальном проекте вы бы клонировали репозиторий.  \n","Для целей семинара создадим пустой Git-репозиторий прямо в среде и инициализируем DVC.\n","\n","Шаги:\n","1. Инициализировать Git и настроить имя/почту (локально для этой папки).\n","2. Инициализировать DVC.\n","3. Зафиксировать первый коммит.\n"],"metadata":{"id":"O5yalledxFpc"}},{"cell_type":"code","source":["# создадим рабочую папку проекта (по желанию можно пропустить и работать в корне)\n","import os, shutil, subprocess, textwrap, sys, json, pathlib\n","\n","project_dir = \"mlops_dvc_demo\"\n","if os.path.exists(project_dir):\n","    shutil.rmtree(project_dir)\n","os.makedirs(project_dir, exist_ok=True)\n","%cd $project_dir\n","\n","# инициализация Git\n","!git init -q\n","!git config user.name \"student\"\n","!git config user.email \"student@example.com\"\n","\n","# инициализация DVC\n","!dvc init -q\n","\n","# базовые служебные файлы\n","open(\".gitignore\", \"a\").close()\n","open(\".dvcignore\", \"a\").close()\n","\n","# первый коммит\n","!git add .\n","!git commit -m \"Init Git + DVC\"\n","!git log --oneline -n 1\n"],"metadata":{"id":"vblZVgY-xLcI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3. Добавление датасета в DVC**\n","\n","Сымитируем наличие датасета: сформируем `data/train.csv` на основе Iris.  \n","Затем:\n","- добавим файл в DVC (`dvc add`),\n","- проверим, что появился мета-файл `train.csv.dvc` и запись в `.gitignore`,\n","- зафиксируем изменения в Git.\n","\n","Важно: **сам CSV не хранится в Git**, в репозиторий попадут только его метаданные.\n"],"metadata":{"id":"ELGGICM9xN-J"}},{"cell_type":"code","source":["# создадим папку и сгенерируем небольшой CSV (Iris)\n","import pandas as pd\n","from sklearn import datasets\n","import os\n","\n","os.makedirs(\"data\", exist_ok=True)\n","iris = datasets.load_iris(as_frame=True)\n","df = iris.frame.rename(columns={\"target\": \"label\"})\n","df.to_csv(\"data/train.csv\", index=False)\n","\n","# добавим в DVC\n","!dvc add data/train.csv -q\n","\n","# посмотрим, что появилось\n","!ls -la data\n","print(\"\\nСодержимое .gitignore:\")\n","print(open(\".gitignore\").read())\n","\n","# зафиксируем в Git метаданные датасета\n","!git add data/.gitignore data/train.csv.dvc\n","!git commit -m \"Add dataset v1 via DVC\"\n","!git status -s\n"],"metadata":{"id":"jH01ifWoxPl_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4. Подключение remote-хранилища и отправка данных**\n","\n","DVC хранит сами файлы (большие данные/модели) в удалённом хранилище.  \n","Для демонстрации используем **локальную папку** как remote.\n","\n","Шаги:\n","1. Добавить remote `localstorage` и сделать его значением по умолчанию (`-d`).\n","2. Отправить данные в хранилище (`dvc push`).\n","3. Убедиться, что данные ушли в папку `./dvc-storage`.\n"],"metadata":{"id":"M9_K4XZ0xRSk"}},{"cell_type":"code","source":["# добавим локальный remote\n","!dvc remote add -d localstorage ./dvc-storage\n","!git add .dvc/config\n","!git commit -m \"Configure DVC remote storage (local)\"\n","\n","# отправим данные\n","!dvc push -q\n","\n","# проверим, что в dvc-storage появились объекты\n","!ls -R dvc-storage | head -n 50\n"],"metadata":{"id":"APodGZntxTWV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **5. Имитация воспроизведения у коллеги (pull)**\n","\n","Проверим типичный сценарий:\n","- «коллега» клонирует репозиторий,\n","- выполняет `dvc pull`,\n","- получает ту же версию датасета.\n","\n","Мы смоделируем это, удалив локальные данные и восстановив их из хранилища.\n"],"metadata":{"id":"AEW5NC0UxVjF"}},{"cell_type":"code","source":["# удалим локальный файл данных, оставив только метаданные .dvc\n","import os, shutil\n","if os.path.exists(\"data/train.csv\"):\n","    os.remove(\"data/train.csv\")\n","\n","print(\"До pull, есть ли data/train.csv? ->\", os.path.exists(\"data/train.csv\"))\n","\n","# восстановим данными из remote\n","!dvc pull -q\n","\n","print(\"После pull, есть ли data/train.csv? ->\", os.path.exists(\"data/train.csv\"))\n","!wc -l data/train.csv\n"],"metadata":{"id":"MImR81hTxXp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **6. Версионирование модели через DVC**\n","\n","Обучим простую модель (LogisticRegression) из `data/train.csv`,  \n","сохраним её как `models/model.pkl` и добавим в DVC.\n","\n","Шаги:\n","1. Написать короткий `train.py` (читает CSV, обучает, сохраняет модель).\n","2. Запустить `python train.py`.\n","3. Добавить `models/model.pkl` в DVC и отправить в remote (`dvc push`).\n"],"metadata":{"id":"0v61Pr37xZJy"}},{"cell_type":"code","source":["# создадим скрипт обучения\n","os.makedirs(\"models\", exist_ok=True)\n","train_py = r\"\"\"\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","import joblib, os\n","\n","df = pd.read_csv(\"data/train.csv\")\n","X = df.drop(\"label\", axis=1)\n","y = df[\"label\"]\n","\n","model = LogisticRegression(max_iter=300)\n","model.fit(X, y)\n","\n","os.makedirs(\"models\", exist_ok=True)\n","joblib.dump(model, \"models/model.pkl\")\n","print(\"Saved models/model.pkl\")\n","\"\"\"\n","open(\"train.py\", \"w\").write(train_py)\n","\n","# зависимости\n","!pip install scikit-learn joblib -q\n","\n","# обучим модель\n","!python train.py\n","\n","# добавим модель в DVC и запушим в remote\n","!dvc add models/model.pkl -q\n","!git add models/model.pkl.dvc models/.gitignore train.py\n","!git commit -m \"Add model v1 via DVC\"\n","!dvc push -q\n","\n","# проверим, что файл модели можно восстановить\n","!rm -f models/model.pkl\n","print(\"Файл модели удалён локально:\", not os.path.exists(\"models/model.pkl\"))\n","!dvc pull -q\n","print(\"Файл модели восстановлён:\", os.path.exists(\"models/model.pkl\"))\n"],"metadata":{"id":"3idc0jBrxae1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **7. Пайплайны DVC (dvc.yaml) и воспроизведение**\n","\n","DVC позволяет описать связи «данные → код → артефакты» в `dvc.yaml`.  \n","Добавим простейший пайплайн с одной стадией `train`:\n","\n","- `cmd`: как запустить обучение;\n","- `deps`: зависимости (скрипты, данные);\n","- `outs`: выходы (модель).\n","\n","После этого командой `dvc repro` можно автоматически выявить,  \n","что нужно пересчитать (например, если изменились данные или код).\n"],"metadata":{"id":"TBK5Uk3Lxg2B"}},{"cell_type":"code","source":["dvc_yaml = \"\"\"stages:\n","  train:\n","    cmd: python train.py\n","    deps:\n","      - train.py\n","      - data/train.csv\n","    outs:\n","      - models/model.pkl\n","\"\"\"\n","open(\"dvc.yaml\", \"w\").write(dvc_yaml)\n","\n","!git add dvc.yaml\n","!git commit -m \"Add DVC pipeline (train stage)\"\n","\n","# проверим воспроизведение\n","!dvc repro -q\n","!echo \"Пайплайн успешно воспроизведён.\"\n"],"metadata":{"id":"JpBlnC17xhIv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **8. Откат версий данных/модели (Git + DVC checkout)**\n","\n","Типичный сценарий:\n","1. Меняем датасет (например, фильтруем часть строк), коммитим изменения — получаем **v2**.\n","2. Хотим вернуться к **v1**: делаем `git checkout <commit>` и `dvc checkout`.\n","\n","Ниже мы:\n","- создадим **v2** датасета,\n","- зафиксируем его,\n","- затем вернёмся на предыдущий коммит и восстановим **v1**.\n"],"metadata":{"id":"jFBo0Iwfxiya"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Сформируем версию v2: отфильтруем часть строк\n","df = pd.read_csv(\"data/train.csv\")\n","df_v2 = df.sample(frac=0.8, random_state=123).reset_index(drop=True)\n","df_v2.to_csv(\"data/train.csv\", index=False)\n","\n","# Обновим версию файла в DVC\n","!dvc add data/train.csv -q\n","!git add data/train.csv.dvc data/.gitignore\n","!git commit -m \"Dataset v2 (filtered 80%)\"\n","!dvc push -q\n","\n","print(\"Текущая длина данных (v2):\")\n","!wc -l data/train.csv\n","\n","# сохраним id текущего и предыдущего коммитов\n","last2 = !git log --pretty=format:'%H' -n 2\n","curr_commit = last2[0]\n","prev_commit = last2[1]\n","print(\"\\nТекущий коммит:\", curr_commit)\n","print(\"Предыдущий коммит:\", prev_commit)\n","\n","# переключимся на предыдущий (где была v1) и выполним dvc checkout\n","!git checkout -q $prev_commit\n","!dvc checkout -q\n","\n","print(\"\\nПосле отката к v1 длина данных:\")\n","!wc -l data/train.csv\n"],"metadata":{"id":"yPGPmF3rxmR2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **9. Обсуждение: DVC vs MLflow и интеграция**\n","\n","- **MLflow** — про эксперименты: параметры, метрики, артефакты, модели, Registry.  \n","- **DVC** — про данные и артефакты на уровне файлов/папок и их воспроизводимость (пайплайны).\n","\n","Как связать:\n","- использовать MLflow для логирования метрик/моделей,\n","- хранить сами датасеты/модели в DVC remote,\n","- запускать пайплайны `dvc repro` в CI/CD, перед шагом обучения/оценки.\n","\n","Практические вопросы:\n","- Какие remote-хранилища использовать (S3/GCS/Azure/SSH/локальные)?\n","- Где хранить секреты (доступ к облачным бакетам)?\n","- Как кэшировать данные на CI, чтобы ускорить `dvc pull`/`dvc push`?\n"],"metadata":{"id":"IkKIxw72xnzf"}},{"cell_type":"code","source":["!pip install dvc mlflow scikit-learn pandas numpy matplotlib"],"metadata":{"id":"YeiF47TcCWmo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Шаг 1. Инициализация DVC\n","\n","DVC — это инструмент для:\n","\n","- версионирования данных (как Git для данных),\n","- построения воспроизводимых ML-пайплайнов,\n","- автоматического трекинга метрик и артефактов.\n","\n","Создадим структуру проекта:\n","\n","project/\n","\n","data/\n","\n","src/\n","\n","dvc.yaml\n","\n","params.yaml\n","\n","mlruns/ (для MLflow)"],"metadata":{"id":"Gsz0zNmXCZLc"}},{"cell_type":"markdown","source":["Инициализируем DVC:"],"metadata":{"id":"KMvgyKtNCgUc"}},{"cell_type":"code","source":["!dvc init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlsacbN7CiFE","executionInfo":{"status":"ok","timestamp":1763571284814,"user_tz":300,"elapsed":121,"user":{"displayName":"Maxim Doronkin","userId":"06116806135204292296"}},"outputId":"dd634f00-802c-4071-816e-6e218143549a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: dvc: command not found\n"]}]},{"cell_type":"markdown","source":["## Шаг 2. Генерация данных и их версионирование\n","\n","Создадим простой набор данных (train.csv), который будем отслеживать в DVC."],"metadata":{"id":"KyzkwS2YCjwy"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","df = pd.DataFrame({\n","    \"x\": np.linspace(-3, 3, 200),\n","})\n","df[\"y\"] = 2 * df[\"x\"] + np.random.normal(0, 1, size=len(df))\n","\n","df.to_csv(\"data.csv\", index=False)\n","df.head()\n"],"metadata":{"id":"U5eROZIfCWsR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Шаг 3. Добавляем данные под контроль DVC\n","\n","Эта команда создаёт:\n","\n","- `data.csv.dvc` — мета-файл\n","- данные переносятся в `.dvc/cache/`\n","\n"],"metadata":{"id":"N2ZeVFCACnEy"}},{"cell_type":"code","source":["!dvc add data.csv\n"],"metadata":{"id":"n6KjzB6RCWvR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Шаг 4. Параметры обучения (params.yaml)\n","\n","DVC умеет подхватывать параметры из файла `params.yaml`.\n","\n"],"metadata":{"id":"jx9SQNOtCpsm"}},{"cell_type":"code","source":["%%writefile params.yaml\n","train:\n","  test_size: 0.2\n","  random_state: 42\n","  alpha: 0.1\n"],"metadata":{"id":"KgzB8YOYCWyH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Шаг 5. Скрипт обучения модели с MLflow внутри DVC stage\n","\n","Это ключевой момент семинара:\n","**MLflow будет логировать параметры и метрики, а DVC — контролировать пайплайн.**\n","\n"],"metadata":{"id":"02_UdO-ZCsch"}},{"cell_type":"code","source":["%%writefile train.py\n","import mlflow\n","import pandas as pd\n","import yaml\n","import numpy as np\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","# Загружаем параметры\n","params = yaml.safe_load(open(\"params.yaml\"))[\"train\"]\n","\n","# DVC читает данные отслеживаемые в data.csv.dvc\n","df = pd.read_csv(\"data.csv\")\n","X = df[[\"x\"]]\n","y = df[\"y\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=params[\"test_size\"],\n","    random_state=params[\"random_state\"]\n",")\n","\n","model = Ridge(alpha=params[\"alpha\"])\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","\n","# Логируем в MLflow\n","mlflow.set_tracking_uri(\"file://\" + __import__(\"os\").path.abspath(\"mlruns\"))\n","mlflow.set_experiment(\"dvc_pipeline_experiment\")\n","\n","with mlflow.start_run():\n","    mlflow.log_param(\"alpha\", params[\"alpha\"])\n","    mlflow.log_metric(\"mse\", mse)\n","    mlflow.sklearn.log_model(model, \"model\")\n","\n","# Сохраняем метрики для DVC\n","with open(\"metrics.json\", \"w\") as f:\n","    f.write('{\"mse\": %f}' % mse)\n"],"metadata":{"id":"EWPP825CCupw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Шаг 6. Создаём DVC пайплайн (dvc.yaml)\n","\n","Здесь происходит магия:\n","\n","- DVC знает, что входные данные — `data.csv`\n","- параметры — `params.yaml`\n","- скрипт запуска — `python train.py`\n","- выход — `metrics.json`\n","\n"],"metadata":{"id":"-2tokbYZCwXB"}},{"cell_type":"code","source":["%%writefile dvc.yaml\n","stages:\n","  train:\n","    cmd: python train.py\n","    deps:\n","      - train.py\n","      - data.csv\n","      - params.yaml\n","    metrics:\n","      - metrics.json:\n","          cache: false\n"],"metadata":{"id":"SPjlxDnqCyEh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Шаг 7. Запускаем пайплайн\n","\n"],"metadata":{"id":"Dqh0KARDC0H-"}},{"cell_type":"code","source":["!dvc repro\n"],"metadata":{"id":"x7c1D6zoC2AU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Результат: настоящая мини-MLOps система\n","\n","Теперь у нас:\n","\n","### ✔ DVC\n","- отслеживает данные\n","- управляет пайплайном\n","- знает, что изменилось и когда нужно пересчитать\n","\n","### ✔ MLflow\n","- логирует эксперименты\n","- хранит модели\n","- визуализирует метрики\n","\n","### ✔ Связка DVC + MLflow\n","- полная воспроизводимость\n","- версионность данных\n","- версионность моделей\n","- автоматическое обучение при изменении данных или параметров\n","\n","### Это и есть современный ML workflow.\n"],"metadata":{"id":"T0T_HUORC3EF"}},{"cell_type":"markdown","source":["# Что можно добавить на семинаре\n","\n","- удалённые хранилища DVC (SSH / S3)\n","- GitHub + DVC + MLflow — полный CI/CD цикл\n","- DVC CML: автоматические эксперименты по pull-request\n","- Автоматический выбор победителя через MLflow + DVC metrics\n","\n","Готов подготовить полный модуль, если хочешь развить курс дальше.\n"],"metadata":{"id":"GAc205lhC4ob"}},{"cell_type":"markdown","source":["## **10. Чек-лист к концу семинара**\n","\n","К моменту завершения семинара студент должен уметь продемонстрировать:\n","\n","1. **Инициализацию проекта**  \n","   - Создан Git-репозиторий.  \n","   - Выполнен `dvc init`, первый коммит зафиксирован.\n","\n","2. **Версионирование датасета**  \n","   - Файл `data/train.csv` добавлен в DVC (`dvc add`).  \n","   - Появились файлы `train.csv.dvc` и запись в `.gitignore`.  \n","   - Коммит с сообщением `\"Add dataset v1 via DVC\"` присутствует в истории.\n","\n","3. **Подключение remote-хранилища**  \n","   - Настроено локальное хранилище `./dvc-storage`.  \n","   - Выполнен `dvc push`, данные успешно отправлены.\n","\n","4. **Воспроизведение данных**  \n","   - После удаления локальных данных команда `dvc pull` восстанавливает датасет из remote.\n","\n","5. **Версионирование модели**  \n","   - Модель обучена (скрипт `train.py`) и сохранена как `models/model.pkl`.  \n","   - Файл добавлен в DVC и загружен в хранилище.\n","\n","6. **Пайплайн `dvc.yaml`**  \n","   - Создана стадия `train` с зависимостями и выходами.  \n","   - Команда `dvc repro` успешно воспроизводит пайплайн.\n","\n","7. **Откат версий**  \n","   - После перехода на предыдущий коммит и `dvc checkout` восстанавливается версия `v1` датасета.\n","\n","8. **Общее понимание**  \n","   - Студент может объяснить, чем DVC отличается от MLflow и как они дополняют друг друга.\n","\n","> **Результат:** в репозитории присутствуют все артефакты (`.dvc`, `dvc.yaml`, `train.py`, `data/`, `models/`), а пайплайн полностью воспроизводим с помощью `dvc repro`.\n"],"metadata":{"id":"HMDGscBWxtlL"}}]}